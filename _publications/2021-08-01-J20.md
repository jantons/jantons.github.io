---
title: "Emotion visualization in Virtual Reality: An integrative review."
authors: "Pinilla, A., Garcia, J. A., Raffe, W., Voigt-Antons, J.-N., Spang, R. & Möller, S."
collection: publications
category: "manuscripts"
permalink: /publication/2021-08-01-J20
excerpt: 'A cluster of research in Affective Computing suggests that it is possible to infer some characteristics of users’ affective states by analyzing their electrophysiological activity in real-time. However, it is not clear how to use the information extracted from electrophysiological signals to create visual representations of the affective states of Virtual Reality (VR) users. Visualization of users’ affective states in VR can lead to biofeedback therapies for mental health care. Understanding how to visualize affective states in VR requires an interdisciplinary approach that integrates psychology, electrophysiology, and audio-visual design. Therefore, this review aims to integrate previous studies from these fields to understand how to develop virtual environments that can automatically create visual representations of users’ affective states. The manuscript addresses this challenge in four sections: First, theories related to emotion and affect are summarized. Second, evidence suggesting that visual and sound cues tend to be associated with affective states are discussed. Third, some of the available methods for assessing affect are described. The fourth and final section contains five practical considerations for the development of virtual reality environments for affect visualization.'
date: 2021-08-01
venue: 'Front. Virtual Real.'
paperurl: 'https://doi.org/10.3389/frvir.2021.630731'
citation: 'Pinilla, A., Garcia, J. A., Raffe, W., Voigt-Antons, J.-N., Spang, R. &amp; Möller, S. (2021). Emotion visualization in Virtual Reality: An integrative review. Front. Virtual Real. 2:630731. https://doi.org/10.3389/frvir.2021.630731'
---

<a href='https://doi.org/10.3389/frvir.2021.630731'>Download publication here.</a>

A cluster of research in Affective Computing suggests that it is possible to infer some characteristics of users’ affective states by analyzing their electrophysiological activity in real-time. However, it is not clear how to use the information extracted from electrophysiological signals to create visual representations of the affective states of Virtual Reality (VR) users. Visualization of users’ affective states in VR can lead to biofeedback therapies for mental health care. Understanding how to visualize affective states in VR requires an interdisciplinary approach that integrates psychology, electrophysiology, and audio-visual design. Therefore, this review aims to integrate previous studies from these fields to understand how to develop virtual environments that can automatically create visual representations of users’ affective states. The manuscript addresses this challenge in four sections: First, theories related to emotion and affect are summarized. Second, evidence suggesting that visual and sound cues tend to be associated with affective states are discussed. Third, some of the available methods for assessing affect are described. The fourth and final section contains five practical considerations for the development of virtual reality environments for affect visualization.

Recommended citation: Pinilla, A., Garcia, J. A., Raffe, W., Voigt-Antons, J.-N., Spang, R. & Möller, S. (2021). Emotion visualization in Virtual Reality: An integrative review. Front. Virtual Real. 2:630731. https://doi.org/10.3389/frvir.2021.630731